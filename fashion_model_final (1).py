# -*- coding: utf-8 -*-
"""fashion_model_final.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1v37RQxINujb0Z2BCcXSGPCw7IxLdsvC5

Adım Adım Ayrıntılandırma:


*   captured_filename = take_photo():
Bu fonksiyon, JavaScript kullanarak kullanıcının web kamerasından bir görüntü yakalar ve yakalanan görüntünün kaydedildiği dosya adını döndürür. take_photo fonksiyonu, kullanıcının fotoğrafı çekmesi için bir düğme görüntüler ve fotoğraf 'photo.jpg' olarak kaydedilir.


---




*   preprocessed_filename = remove_background_rembg(captured_filename):
Bu adım, yakalanan görüntüyü rembg kitaplığını kullanarak arka planı kaldırmak için işleyen remove_background_rembg fonksiyonunu çağırır. Ortaya çıkan görüntü yalnızca şeffaf bir arka plana sahip ön plan nesnesini (bu durumda giysi) içerecektir.
Daha sonra görüntü 'preprocessed_clothing_rembg.png' adıyla kaydedilir.



---



*   apparel_type = predict_apparel(preprocessed_filename):
predict_apparel fonksiyonu, önceden eğitilmiş bir model (resnet50) kullanarak giysi türünü sınıflandırmak için önceden işlenmiş görüntüyü (arka planı kaldırılmış) işler. Tahmin edilen giyim türünü (örneğin Gömlek, Tişört vb.) döndürür.


---



* season, year, usage = predict_multi_label(preprocessed_filename):
Bu adım, giyimin mevsimi, yılı ve kullanımı için çok etiketli tahminler yapmak üzere predict_multi_label işlevini kullanır. İşlev, görüntüyü önceden eğitilmiş modelle işler ve tahmin edilen mevsimi (örneğin Yaz, Kış), yılı (örneğin 2022) ve kullanımı (örneğin Günlük, Spor) döndürür.
  



---




*   avg_color = calculate_average_color_no_white(preprocessed_filename):
calculate_average_color_no_white işlevi, beyaz pikseller hariç olmak üzere görüntünün ortalama rengini hesaplar. Görüntüyü bir diziye dönüştürmek için NumPy kullanır ve beyaz olmayan piksellerin ortalama RGB değerini hesaplar.
Ortalama rengi RGB biçiminde (tamsayılar dizisi) döndürür.



---



*   avg_color_name = closest_named_color(avg_color):
Bu adım, önceki adımda hesaplanan ortalama renge en yakın adlandırılmış rengi bulur. RGB değerlerini matplotlib.colors kütüphanesindeki bilinen renk adlarıyla karşılaştırır ve en yakın rengin adını döndürür (örneğin, "koyu gri").



---





*   avg_color_hex = '#{:02x}{:02x}{:02x}'.format(avg_color[0], avg_color[1], avg_color[2]):
Bu satır, ortalama RGB rengini onaltılık eşdeğerine dönüştürür. RGB değerlerini #RRGGBB biçiminde bir dizeye biçimlendirir.


---


*   display(PILImage.open((preprocessed_filename))):
Önceden işlenmiş görüntüyü (arka planı kaldırılmış olarak) çıktıda görüntüler.


---



*   Yazdırma ifadeleri:
Komut dosyası, tahmin edilen giyim türünü, mevsimi, yılı, kullanımı, baskın rengi (RGB olarak), baskın rengi (hex olarak) ve baskın rengin adını yazdırır.


---


*   İstisna işleme (except Exception as e):
Try bloğunun yürütülmesi sırasında herhangi bir hata oluşursa, except bloğu tarafından yakalanır ve istisnayı açıklayan bir hata mesajı yazdırılır.
"""

!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
!pip install kagglehub
!pip install keras
!pip install tqdm

"""# **Apperal Type Prediction Model**"""

import os
import pandas as pd
from PIL import Image
from sklearn.model_selection import train_test_split
import torch
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
import torch.nn as nn
from torchvision import models
from tqdm import tqdm
import matplotlib.pyplot as plt
import kagglehub

# Veri yolları belirleniyor ve Kaggle veri seti indiriliyor
# Kagglehub, belirli bir veri setini programatik olarak indirmek için kullanılıyor
# Kaggle veri setini indiriyoruz. Bu veri seti, moda ürünlerinin görselleri ve meta verilerini içeriyor.
kagglehub.dataset_download("paramaggarwal/fashion-product-images-dataset")
BASE_DIR = "/root/.cache/kagglehub/datasets/paramaggarwal/fashion-product-images-dataset/versions/1/fashion-dataset"
CSV_FILE = os.path.join(BASE_DIR, "styles.csv")  # Meta veri dosyası
IMAGES_DIR = os.path.join(BASE_DIR, "images")    # Görsellerin bulunduğu klasör

# styles.csv dosyasını yükleme ve gerekli sütunları seçme
# Meta veri dosyasını okuyoruz. 'styles.csv' dosyası, ürün ID'leri ve ürün tipleri gibi bilgileri içeriyor.
df = pd.read_csv(CSV_FILE, on_bad_lines='skip')
# Sadece ürün ID'si ve ürün tipi sütunlarını alıyoruz ve eksik verileri kaldırıyoruz.
df = df[["id", "articleType"]].dropna()  # Boş değerleri kaldırıyoruz

# Görsellerin mevcut olup olmadığını kontrol et
# Görsellerin dosya adlarını oluşturuyoruz. Her bir ürün ID'sini '.jpg' ile birleştiriyoruz.
df["image_path"] = df["id"].astype(str) + ".jpg"  # Görsel dosya adını oluşturuyoruz
df = df[df["image_path"].apply(lambda x: os.path.exists(os.path.join(IMAGES_DIR, x)))]

# Sınıf dağılımını kontrol etmeden önce mevcut durum yazdırılıyor
print("Sınıf dağılımı öncesi:")
print(df["articleType"].value_counts())

# Az örnek bulunan sınıfları kaldırmak için bir eşik değeri belirliyoruz
min_samples = 1000  # Her sınıfta minimum 1000 örnek olması gerekiyor
# Sınıf dağılımını analiz ediyoruz. Bu, her bir ürün tipinden kaç adet bulunduğunu kontrol etmek için kullanılır.
class_counts = df["articleType"].value_counts()
valid_classes = class_counts[class_counts >= min_samples].index  # Geçerli sınıfları belirleme
df = df[df["articleType"].isin(valid_classes)]

# Sınıf dağılımını tekrar kontrol ediyoruz
print("\nSınıf dağılımı sonrası:")
print(df["articleType"].value_counts())

# Sınıf isimlerini sayısal etiketlere (label encoding) dönüştürme
class_to_idx = {cls: idx for idx, cls in enumerate(df["articleType"].unique())}
idx_to_class = {v: k for k, v in class_to_idx.items()}
df["label"] = df["articleType"].map(class_to_idx)  # Sınıfları etiketlere dönüştürme

# Veriyi eğitim ve doğrulama setlerine ayırma
# Veriyi eğitim ve doğrulama setlerine ayırıyoruz. Stratify parametresi, sınıf dağılımını korumak için kullanılır.
train_df, val_df = train_test_split(
    df, test_size=0.2, stratify=df["label"], random_state=42
)

# Özel veri seti sınıfı
class FashionDataset(Dataset):
    """
    Özel bir PyTorch Dataset sınıfı.

    Attributes:
        dataframe (pd.DataFrame): Veri çerçevesi (id, etiket, image_path bilgileri içerir).
        images_dir (str): Görsellerin bulunduğu dizin.
        transform (torchvision.transforms.Compose): Görsellere uygulanacak dönüşümler.
    """

    def __init__(self, dataframe, images_dir, transform=None):
        self.dataframe = dataframe
        self.images_dir = images_dir
        self.transform = transform

    def __len__(self):
        """
        Veri setindeki toplam örnek sayısını döndürür.
        """
        return len(self.dataframe)

    def __getitem__(self, idx):
        """
        Belirli bir indeksteki veriyi döndürür.

        Args:
            idx (int): İndeks değeri.

        Returns:
            image (PIL.Image): Görüntü verisi.
            label (int): Görüntüye ait etiket.
        """
        row = self.dataframe.iloc[idx]
        img_path = os.path.join(self.images_dir, row["image_path"])
        image = Image.open(img_path).convert("RGB")  # Görseller RGB formatına dönüştürülüyor
        label = row["label"]

        if self.transform:
            image = self.transform(image)

        return image, label

# Eğitim ve doğrulama için dönüşüm tanımları (data augmentation)
transform_train = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),  # Görselleri yatayda çevirme
    transforms.RandomRotation(15),      # Görselleri 15 dereceye kadar döndürme
    transforms.ToTensor(),              # Görselleri tensöre dönüştürme
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

transform_val = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Dataset ve DataLoader oluşturma
train_dataset = FashionDataset(train_df, IMAGES_DIR, transform=transform_train)
val_dataset = FashionDataset(val_df, IMAGES_DIR, transform=transform_val)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# ResNet-50 modelini yükleme ve özelleştirme
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# ResNet-50 modelini önceden eğitilmiş ağırlıklarla yüklüyoruz. Bu model, görüntü sınıflandırmada yaygın olarak kullanılır.
model = models.resnet50(pretrained=True)  # Önceden eğitilmiş ResNet-50 modeli
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, len(class_to_idx))  # Çıkış katmanını sınıf sayısına göre düzenleme
model = model.to(device)

# Kayıp fonksiyonu ve optimizer tanımı
# CrossEntropyLoss, çok sınıflı sınıflandırma problemleri için uygun bir kayıp fonksiyonudur.
criterion = nn.CrossEntropyLoss()  # Çok sınıflı sınıflandırma için uygun kayıp fonksiyonu
# Optimizasyon algoritması olarak Adam kullanıyoruz. Bu, adaptif öğrenme oranı ile etkin bir şekilde öğrenmeyi sağlar.
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)

# Eğitim döngüsü (Early Stopping eklenmiş hali)
def train_model_with_early_stopping(model, criterion, optimizer, train_loader, val_loader, num_epochs=20, patience=3):
    """
    Modeli eğitmek için kullanılan eğitim döngüsü. Early Stopping uygulanmıştır.

    Args:
        model (torch.nn.Module): Eğitim yapılacak model.
        criterion: Kayıp fonksiyonu.
        optimizer: Optimizasyon algoritması.
        train_loader (DataLoader): Eğitim veri yükleyicisi.
        val_loader (DataLoader): Doğrulama veri yükleyicisi.
        num_epochs (int): Toplam epoch sayısı.
        patience (int): Early Stopping için maksimum sabır süresi.

    Returns:
        model: En iyi doğrulama kaybıyla eğitilmiş model.
        train_losses (list): Eğitim kayıpları.
        val_losses (list): Doğrulama kayıpları.
        train_accuracies (list): Eğitim doğrulukları.
        val_accuracies (list): Doğrulama doğrulukları.
    """
    train_losses, val_losses = [], []
    train_accuracies, val_accuracies = [], []
    best_val_loss = float('inf')  # Başlangıçta çok büyük bir değerle başlatılıyor
    patience_counter = 0
    best_model_weights = None

    for epoch in range(num_epochs):
        model.train()
        running_loss, running_corrects = 0.0, 0

        # Eğitim aşaması
        for inputs, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs} - Training"):
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()

            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            _, preds = torch.max(outputs, 1)
            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels.data)

        epoch_loss = running_loss / len(train_loader.dataset)
        epoch_acc = running_corrects.double() / len(train_loader.dataset)
        train_losses.append(epoch_loss)
        train_accuracies.append(epoch_acc.item())
        print(f"Train - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}")

        # Doğrulama aşaması
        model.eval()
        val_loss, val_corrects = 0.0, 0
        with torch.no_grad():
            for inputs, labels in tqdm(val_loader, desc=f"Epoch {epoch+1}/{num_epochs} - Validation"):
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)

                _, preds = torch.max(outputs, 1)
                val_loss += loss.item() * inputs.size(0)
                val_corrects += torch.sum(preds == labels.data)

        val_loss /= len(val_loader.dataset)
        val_acc = val_corrects.double() / len(val_loader.dataset)
        val_losses.append(val_loss)
        val_accuracies.append(val_acc.item())
        print(f"Validation - Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}")

        # Early Stopping kontrolü
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_model_weights = model.state_dict()  # En iyi modeli kaydet
            patience_counter = 0  # Eğer iyileşme varsa patience sıfırlanır
        else:
            patience_counter += 1

        # Eğer patience kadar iyileşme yoksa eğitim sonlanır
        if patience_counter >= patience:
            print(f"Early stopping triggered after {epoch+1} epochs.")
            break

    # En iyi modelin ağırlıkları yüklenir
    if best_model_weights is not None:
        model.load_state_dict(best_model_weights)

    return model, train_losses, val_losses, train_accuracies, val_accuracies

# Modeli eğit (Early Stopping ile)
trained_model, train_losses, val_losses, train_accuracies, val_accuracies = train_model_with_early_stopping(
    model, criterion, optimizer, train_loader, val_loader, num_epochs=20, patience=5
)

# Modeli kaydet
# Eğitilmiş modelin ağırlıklarını kaydediyoruz. Bu dosya, daha sonra modelin yeniden yüklenmesi için kullanılabilir.
torch.save(model.state_dict(), "apperal_type_pred_model.pth")

# Check unique classes in the articleType column
print(df.columns)
unique_classes = df["articleType"].unique()
num_classes = len(unique_classes)
print(f"Number of unique classes in articleType: {num_classes}")
print("Classes:", unique_classes)

"""# **Multiple Aspect Prediction Model**"""

import os
import pandas as pd
from PIL import Image
from sklearn.model_selection import train_test_split
import torch
import torchvision.transforms as transforms
from torch.utils.data import DataLoader, Dataset
import torch.nn as nn
from torchvision import models
from tqdm import tqdm
import matplotlib.pyplot as plt
import kagglehub

# Veri yolları belirleniyor ve Kaggle veri seti indiriliyor
# Kagglehub, belirli bir veri setini programatik olarak indirmek için kullanılıyor
# Kaggle veri setini indiriyoruz. Bu veri seti, moda ürünlerinin görselleri ve meta verilerini içeriyor.
# Define paths and download Kaggle dataset
# Kagglehub is used to programmatically download a specific dataset
# Downloading the Kaggle dataset which contains images and metadata of fashion products
kagglehub.dataset_download("paramaggarwal/fashion-product-images-dataset")
BASE_DIR = "/root/.cache/kagglehub/datasets/paramaggarwal/fashion-product-images-dataset/versions/1/fashion-dataset"
CSV_FILE = os.path.join(BASE_DIR, "styles.csv")  # Meta veri dosyası / Metadata file
IMAGES_DIR = os.path.join(BASE_DIR, "images")    # Görsellerin bulunduğu klasör / Directory containing images

# styles.csv dosyasını yükleme ve gerekli sütunları seçme
# Meta veri dosyasını okuyoruz. 'styles.csv' dosyası, ürün ID'leri ve ürün tipleri gibi bilgileri içeriyor.
# Loading styles.csv and selecting relevant columns
# The metadata file 'styles.csv' contains product IDs and types

df = pd.read_csv(CSV_FILE, on_bad_lines='skip')
# Sadece ürün ID'si ve ürün tipi sütunlarını alıyoruz ve eksik verileri kaldırıyoruz.
# Selecting only product ID and type columns, and dropping missing values
df = df[["id", "articleType"]].dropna()  # Boş değerleri kaldırıyoruz / Removing missing values

# Görsellerin mevcut olup olmadığını kontrol et
# Görsellerin dosya adlarını oluşturuyoruz. Her bir ürün ID'sini '.jpg' ile birleştiriyoruz.
# Check if images exist
# Creating image file names by appending '.jpg' to each product ID
df["image_path"] = df["id"].astype(str) + ".jpg"  # Görsel dosya adını oluşturuyoruz / Generating image file names
df = df[df["image_path"].apply(lambda x: os.path.exists(os.path.join(IMAGES_DIR, x)))]

# Sınıf dağılımını kontrol etmeden önce mevcut durum yazdırılıyor
# Checking the class distribution and printing the current state
print("Sınıf dağılımı öncesi:")  # Before filtering classes
print(df["articleType"].value_counts())

# Az örnek bulunan sınıfları kaldırmak için bir eşik değeri belirliyoruz
# Her sınıfta minimum 1000 örnek olması gerekiyor
# Filtering classes with fewer samples based on a threshold
min_samples = 1000  # Minimum number of samples per class
# Sınıf dağılımını analiz ediyoruz. Bu, her bir ürün tipinden kaç adet bulunduğunu kontrol etmek için kullanılır.
# Analyzing class distribution to check the number of instances for each product type
class_counts = df["articleType"].value_counts()
valid_classes = class_counts[class_counts >= min_samples].index  # Geçerli sınıfları belirleme / Identifying valid classes
df = df[df["articleType"].isin(valid_classes)]

# Sınıf dağılımını tekrar kontrol ediyoruz
# Checking the class distribution again
print("\nSınıf dağılımı sonrası:")  # After filtering classes
print(df["articleType"].value_counts())

# Sınıf isimlerini sayısal etiketlere (label encoding) dönüştürme
# Converting class names to numerical labels (label encoding)
class_to_idx = {cls: idx for idx, cls in enumerate(df["articleType"].unique())}
idx_to_class = {v: k for k, v in class_to_idx.items()}
df["label"] = df["articleType"].map(class_to_idx)  # Sınıfları etiketlere dönüştürme / Mapping classes to labels

# Veriyi eğitim ve doğrulama setlerine ayırma
# Veriyi eğitim ve doğrulama setlerine ayırıyoruz. Stratify parametresi, sınıf dağılımını korumak için kullanılır.
# Splitting data into training and validation sets. The stratify parameter ensures class distribution is preserved.
train_df, val_df = train_test_split(
    df, test_size=0.2, stratify=df["label"], random_state=42
)

# Özel veri seti sınıfı / Custom dataset class
class FashionDataset(Dataset):
    """
    Özel bir PyTorch Dataset sınıfı.
    Custom PyTorch Dataset class.

    Attributes:
        dataframe (pd.DataFrame): Veri çerçevesi (id, etiket, image_path bilgileri içerir).
        Dataframe containing id, label, and image_path information.
        images_dir (str): Görsellerin bulunduğu dizin.
        Directory containing the images.
        transform (torchvision.transforms.Compose): Görsellere uygulanacak dönüşümler.
        Transformations to be applied to the images.
    """

    def __init__(self, dataframe, images_dir, transform=None):
        self.dataframe = dataframe
        self.images_dir = images_dir
        self.transform = transform

    def __len__(self):
        """
        Veri setindeki toplam örnek sayısını döndürür.
        Returns the total number of examples in the dataset.
        """
        return len(self.dataframe)

    def __getitem__(self, idx):
        """
        Belirli bir indeksteki veriyi döndürür.
        Returns the data at a specific index.

        Args:
            idx (int): İndeks değeri / Index value.

        Returns:
            image (PIL.Image): Görüntü verisi / Image data.
            label (int): Görüntüye ait etiket / Label for the image.
        """
        row = self.dataframe.iloc[idx]
        img_path = os.path.join(self.images_dir, row["image_path"])
        image = Image.open(img_path).convert("RGB")  # Görseller RGB formatına dönüştürülüyor / Converting images to RGB format
        label = row["label"]

        if self.transform:
            image = self.transform(image)

        return image, label

# Eğitim ve doğrulama için dönüşüm tanımları (data augmentation)
# Defining transformations for training and validation (data augmentation)
transform_train = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.RandomHorizontalFlip(),  # Görselleri yatayda çevirme / Horizontal flip
    transforms.RandomRotation(15),      # Görselleri 15 dereceye kadar döndürme / Rotation up to 15 degrees
    transforms.ToTensor(),              # Görselleri tensöre dönüştürme / Convert images to tensors
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

transform_val = transforms.Compose([
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# Dataset ve DataLoader oluşturma / Creating dataset and DataLoader
train_dataset = FashionDataset(train_df, IMAGES_DIR, transform=transform_train)
val_dataset = FashionDataset(val_df, IMAGES_DIR, transform=transform_val)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# ResNet-50 modelini yükleme ve özelleştirme / Loading and customizing the ResNet-50 model
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
# ResNet-50 modelini önceden eğitilmiş ağırlıklarla yüklüyoruz. Bu model, görüntü sınıflandırmada yaygın olarak kullanılır.
# Loading the ResNet-50 model with pre-trained weights. This model is commonly used for image classification.
model = models.resnet50(pretrained=True)  # Önceden eğitilmiş ResNet-50 modeli / Pre-trained ResNet-50 model
num_ftrs = model.fc.in_features
model.fc = nn.Linear(num_ftrs, len(class_to_idx))  # Çıkış katmanını sınıf sayısına göre düzenleme / Adjusting the output layer for the number of classes
model = model.to(device)

# Kayıp fonksiyonu ve optimizer tanımı / Defining loss function and optimizer
# CrossEntropyLoss, çok sınıflı sınıflandırma problemleri için uygun bir kayıp fonksiyonudur.
# CrossEntropyLoss is suitable for multi-class classification problems.
criterion = nn.CrossEntropyLoss()  # Çok sınıflı sınıflandırma için uygun kayıp fonksiyonu / Loss function for multi-class classification
# Optimizasyon algoritması olarak Adam kullanıyoruz. Bu, adaptif öğrenme oranı ile etkin bir şekilde öğrenmeyi sağlar.
# Using the Adam optimizer, which provides adaptive learning rates for efficient learning.
optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)

# Eğitim döngüsü (Early Stopping eklenmiş hali) / Training loop (with Early Stopping)
def train_model_with_early_stopping(model, criterion, optimizer, train_loader, val_loader, num_epochs=20, patience=3):
    """
    Modeli eğitmek için kullanılan eğitim döngüsü. Early Stopping uygulanmıştır.
    Training loop for the model with Early Stopping implemented.

    Args:
        model (torch.nn.Module): Eğitim yapılacak model / Model to be trained.
        criterion: Kayıp fonksiyonu / Loss function.
        optimizer: Optimizasyon algoritması / Optimization algorithm.
        train_loader (DataLoader): Eğitim veri yükleyicisi / Training data loader.
        val_loader (DataLoader): Doğrulama veri yükleyicisi / Validation data loader.
        num_epochs (int): Toplam epoch sayısı / Total number of epochs.
        patience (int): Early Stopping için maksimum sabır süresi / Maximum patience for Early Stopping.

    Returns:
        model: En iyi doğrulama kaybıyla eğitilmiş model / Model trained with the best validation loss.
        train_losses (list): Eğitim kayıpları / Training losses.
        val_losses (list): Doğrulama kayıpları / Validation losses.
        train_accuracies (list): Eğitim doğrulukları / Training accuracies.
        val_accuracies (list): Doğrulama doğrulukları / Validation accuracies.
    """
    train_losses, val_losses = [], []
    train_accuracies, val_accuracies = [], []
    best_val_loss = float('inf')  # Başlangıçta çok büyük bir değerle başlatılıyor / Initialize with a large value
    patience_counter = 0
    best_model_weights = None

    for epoch in range(num_epochs):
        model.train()
        running_loss, running_corrects = 0.0, 0

        # Eğitim aşaması / Training phase
        for inputs, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs} - Training"):
            inputs, labels = inputs.to(device), labels.to(device)
            optimizer.zero_grad()

            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            _, preds = torch.max(outputs, 1)
            running_loss += loss.item() * inputs.size(0)
            running_corrects += torch.sum(preds == labels.data)

        epoch_loss = running_loss / len(train_loader.dataset)
        epoch_acc = running_corrects.double() / len(train_loader.dataset)
        train_losses.append(epoch_loss)
        train_accuracies.append(epoch_acc.item())
        print(f"Train - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}")

        # Doğrulama aşaması / Validation phase
        model.eval()
        val_loss, val_corrects = 0.0, 0
        with torch.no_grad():
            for inputs, labels in tqdm(val_loader, desc=f"Epoch {epoch+1}/{num_epochs} - Validation"):
                inputs, labels = inputs.to(device), labels.to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)

                _, preds = torch.max(outputs, 1)
                val_loss += loss.item() * inputs.size(0)
                val_corrects += torch.sum(preds == labels.data)

        val_loss /= len(val_loader.dataset)
        val_acc = val_corrects.double() / len(val_loader.dataset)
        val_losses.append(val_loss)
        val_accuracies.append(val_acc.item())
        print(f"Validation - Loss: {val_loss:.4f}, Accuracy: {val_acc:.4f}")

        # Early Stopping kontrolü / Early Stopping check
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            best_model_weights = model.state_dict()  # En iyi modeli kaydet / Save the best model
            patience_counter = 0  # Eğer iyileşme varsa patience sıfırlanır / Reset patience counter if validation improves
        else:
            patience_counter += 1

        # Eğer patience kadar iyileşme yoksa eğitim sonlanır / Stop training if no improvement for 'patience' epochs
        if patience_counter >= patience:
            print(f"Early stopping triggered after {epoch+1} epochs.")
            break

    # En iyi modelin ağırlıkları yüklenir / Load the best model weights
    if best_model_weights is not None:
        model.load_state_dict(best_model_weights)

    return model, train_losses, val_losses, train_accuracies, val_accuracies

# Modeli eğit (Early Stopping ile) / Train the model (with Early Stopping)
trained_model, train_losses, val_losses, train_accuracies, val_accuracies = train_model_with_early_stopping(
    model, criterion, optimizer, train_loader, val_loader, num_epochs=20, patience=5
)

# Modeli kaydet / Save the model
# Eğitilmiş modelin ağırlıklarını kaydediyoruz. Bu dosya, daha sonra modelin yeniden yüklenmesi için kullanılabilir.
# Saving the trained model weights. This file can be used to reload the model later.
torch.save(model.state_dict(), "apperal_type_pred_model.pth")

# Commented out IPython magic to ensure Python compatibility.
# %%capture
# !pip install rembg
# !pip install onnxruntime

"""# **Full Prediction Model**"""

import torch
from torchvision import transforms, models
from torchvision.models.segmentation import deeplabv3_resnet50
from PIL import Image as PILImage
from google.colab.output import eval_js
from base64 import b64decode
from IPython.display import display, Javascript
import numpy as np
import matplotlib.colors as mcolors
import matplotlib.pyplot as plt
import cv2

# Kameradan bir görüntü yakalamak için JavaScript
def take_photo(filename='photo.jpg', quality=0.8):
    """
    Kullanıcının kameradan bir fotoğraf çekmesine olanak tanır ve dosyayı kaydeder.

    Args:
        filename (str): Kaydedilecek dosya adı.
        quality (float): Fotoğraf kalitesi (0-1 arası).

    Returns:
        str: Kaydedilen dosyanın adı.
    """
    js = Javascript('''
        async function takePhoto(quality) {
            const div = document.createElement('div');
            const capture = document.createElement('button');
            capture.textContent = 'Capture';
            div.appendChild(capture);

            const video = document.createElement('video');
            video.style.display = 'block';
            const stream = await navigator.mediaDevices.getUserMedia({video: true});

            document.body.appendChild(div);
            div.appendChild(video);
            video.srcObject = stream;
            await video.play();

            google.colab.output.setIframeHeight(document.documentElement.scrollHeight, true);
            await new Promise((resolve) => capture.onclick = resolve);

            const canvas = document.createElement('canvas');
            canvas.width = video.videoWidth;
            canvas.height = video.videoHeight;
            canvas.getContext('2d').drawImage(video, 0, 0);
            stream.getVideoTracks()[0].stop();
            div.remove();
            return canvas.toDataURL('image/jpeg', quality);
        }
    ''')
    display(js)
    data = eval_js('takePhoto({})'.format(quality))
    binary = b64decode(data.split(',')[1])
    with open(filename, 'wb') as f:
        f.write(binary)
    return filename

# Ön işleme için dönüşümler
transform = transforms.Compose([
    transforms.Resize((224, 224)),  # Resizing the image to 224x224
    transforms.ToTensor(),          # Converting image to tensor
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalization
])

# Segmentasyon için önceden eğitilmiş DeepLabV3 modelini yükleme
segmentation_model = deeplabv3_resnet50(pretrained=True)
segmentation_model = segmentation_model.eval().cuda()

# Arka planı kaldırmak ve sadece kıyafetleri tutmak için fonksiyon
from rembg import remove
from PIL import Image
import io

def remove_background_rembg(image_path):
    """
    Rembg kullanarak bir görüntünün arka planını kaldırır ve şeffaf bir PNG olarak kaydeder.

    Args:
        image_path (str): İşlenecek görüntünün yolu.

    Returns:
        str: Şeffaf arka planlı görüntünün kaydedildiği yol.
    """
    with open(image_path, "rb") as file:
        input_image = file.read()

    output_image = remove(input_image)

    result_image = Image.open(io.BytesIO(output_image)).convert("RGBA")

    preprocessed_path = "preprocessed_clothing_rembg.png"
    result_image.save(preprocessed_path)

    return preprocessed_path

# Çoklu etiket sınıflandırma modeli tanımlaması
class FashionModel(torch.nn.Module):
    """
    Multi-label sınıflandırma için bir model tanımlanır (mevsim, yıl, kullanım).

    Args:
        num_classes_season (int): Mevsim sınıfları sayısı.
        num_classes_year (int): Yıl sınıfları sayısı.
        num_classes_usage (int): Kullanım sınıfları sayısı.
    """
    def __init__(self, num_classes_season, num_classes_year, num_classes_usage):
        super(FashionModel, self).__init__()
        self.base_model = models.resnet50(pretrained=True)
        self.base_model = torch.nn.Sequential(*list(self.base_model.children())[:-1])  # Son FC katmanını kaldır
        self.flatten = torch.nn.Flatten()
        self.fc_season = torch.nn.Linear(2048, num_classes_season)
        self.fc_year = torch.nn.Linear(2048, num_classes_year)
        self.fc_usage = torch.nn.Linear(2048, num_classes_usage)

    def forward(self, x):
        """
        Modelin ileri aktarımı.

        Args:
            x (torch.Tensor): Giriş tensörü.

        Returns:
            tuple: Mevsim, yıl ve kullanım çıktıları.
        """
        x = self.base_model(x)
        x = self.flatten(x)
        season = self.fc_season(x)
        year = self.fc_year(x)
        usage = self.fc_usage(x)
        return season, year, usage

# Görüntü renklerini LAB renk uzayında normalize et
def color_space_normalization(image_path):
    """
    Görüntüyü LAB renk uzayında normalize eder ve normalize edilmiş görüntüyü döndürür.

    Args:
        image_path (str): Normalize edilecek görüntünün yolu.

    Returns:
        PIL.Image: Normalize edilmiş görüntü.
    """
    image = cv2.imread(image_path)
    lab_image = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
    l_channel, a_channel, b_channel = cv2.split(lab_image)
    l_channel_eq = cv2.equalizeHist(l_channel)
    lab_image_eq = cv2.merge((l_channel_eq, a_channel, b_channel))
    normalized_image = cv2.cvtColor(lab_image_eq, cv2.COLOR_LAB2RGB)
    return PILImage.fromarray(normalized_image)

# Renk uzayı normalizasyonu ile güncellenmiş dönüşümler
def preprocess_image_with_color_normalization(image_path):
    """
    Görüntüyü LAB renk uzayında normalize eder ve yeniden boyutlandırır.

    Args:
        image_path (str): İşlenecek görüntünün yolu.

    Returns:
        torch.Tensor: İşlenmiş tensör görüntüsü.
    """
    normalized_image = color_space_normalization(image_path)
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])
    return transform(normalized_image)

# Tahmin fonksiyonları
def predict_multi_label(image_path):
    """
    Bir görüntü üzerinde çoklu etiket sınıflandırması yapar.

    Args:
        image_path (str): Sınıflandırılacak görüntünün yolu.

    Returns:
        tuple: Mevsim, yıl ve kullanım tahminleri.
    """
    image_tensor = preprocess_image_with_color_normalization(image_path).unsqueeze(0).cuda()

    with torch.no_grad():
        outputs_season, outputs_year, outputs_usage = multi_label_model(image_tensor)

    _, predicted_season = torch.max(outputs_season.data, 1)
    _, predicted_year = torch.max(outputs_year.data, 1)
    _, predicted_usage = torch.max(outputs_usage.data, 1)

    season_labels = ['Spring', 'Summer', 'Fall', 'Winter']
    year_labels = ['2011', '2012', '2016', '2017', '2015', '2014', '2010', '2013', '2018', '2019', '2007', '2009',
                   '2008']
    usage_labels = ['Casual', 'Sports', 'Formal', 'Party', 'Beach']

    season_pred = season_labels[predicted_season.item()]
    year_pred = year_labels[predicted_year.item()]
    usage_pred = usage_labels[predicted_usage.item()]
    return season_pred, year_pred, usage_pred

# Kıyafetin ortalama rengini hesaplamak için fonksiyon
def calculate_average_color_no_white(image_path):
    """
    Bir görüntünün ortalama rengini hesaplar ve beyaz pikselleri dışlar.

    Args:
        image_path (str): İşlenecek görüntünün yolu.

    Returns:
        tuple: Ortalama RGB rengi.
    """
    image = PILImage.open(image_path).convert("RGB")
    image_array = np.array(image)

    mask = ~np.all(image_array == [255, 255, 255], axis=-1)  # Beyaz olmayan pikselleri seç

    if np.any(mask):
        avg_color = np.mean(image_array[mask], axis=0).astype(int)
    else:
        avg_color = (255, 255, 255)  # Eğer tüm pikseller beyazsa varsayılan beyaz

    return tuple(avg_color)

# Bir RGB renginin en yakın isimlendirilmiş rengini bulmak için fonksiyon
def closest_named_color(rgb_color):
    """
    Bir RGB renginin en yakın isimlendirilmiş rengini bulur.

    Args:
        rgb_color (tuple): RGB renk değerleri.

    Returns:
        str: En yakın isimlendirilmiş renk.
    """
    min_distance = float('inf')
    closest_color_name = None

    for name, hex_value in mcolors.CSS4_COLORS.items():
        r, g, b = mcolors.to_rgb(hex_value)
        rgb_scaled = tuple(int(x * 255) for x in (r, g, b))
        distance = np.sqrt(sum((component1 - component2) ** 2 for component1, component2 in zip(rgb_scaled, rgb_color)))
        if distance < min_distance:
            min_distance = distance
            closest_color_name = name

    return closest_color_name

"""# **Main Script**"""

import torch
from torchvision import transforms, models
from torchvision.models.segmentation import deeplabv3_resnet50
from PIL import Image as PILImage
from google.colab.output import eval_js
from base64 import b64decode
from IPython.display import display, Javascript
import numpy as np
import matplotlib.colors as mcolors
import matplotlib.pyplot as plt
import cv2

# Kameradan bir görüntü yakalamak için JavaScript
# Kullanıcının kameradan bir fotoğraf çekmesine olanak tanır ve dosyayı kaydeder
try:
    captured_filename = take_photo()

    # Görüntüyü ön işleme
    # Arka planı kaldırma ve temizleme işlemi uygulanıyor
    preprocessed_filename = remove_background_rembg(captured_filename)

    # Sınıflandırma tahminleri
    # Kıyafet türü ve kullanım detaylarını tahmin eder
    apparel_type = predict_apparel(preprocessed_filename)
    season, year, usage = predict_multi_label(preprocessed_filename)

    # Ortalama renk hesaplama
    # Görüntünün baskın rengini beyaz dışındaki renklerle belirler
    avg_color = calculate_average_color_no_white(preprocessed_filename)

    # RGB tahminin isimlendirilmiş renk uzayıyla kıyaslama / RGB nearest color logic
    # Color sonucu
    avg_color_name = closest_named_color(avg_color)

from google.colab import drive
drive.mount('/content/drive')